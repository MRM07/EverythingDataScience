{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Pipeline Support for TPOT Framework",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRM07/EverythingDataScience/blob/master/Text_Pipeline_Support_for_TPOT_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9S3kqUdQzYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56d630d0-2b99-468a-e9f4-27e68486443b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('names')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxgRg0Q0QsyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "db731082-0278-44bb-b74d-5afb88a67a16"
      },
      "source": [
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "import string\n",
        "import spacy \n",
        "import en_core_web_sm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from normalise import normalise\n",
        "\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LabelPropagation from version 0.18 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnbzsRld09r",
        "colab_type": "text"
      },
      "source": [
        "# Pipelining our Pre-Processing /Feature Engg for Datasets which contain Text Data #\n",
        "\n",
        "*   We create a selector transformer that simply returns us  the values of columns by key we pass. This selector is for both numeric/text type \n",
        "\n",
        "\n",
        "# Reusable pipeline\n",
        "\n",
        "* We are going to cretate reusable pipeline, which we could use on any of our NLP projects, again a transformer function. Similar to previous\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CL1rzRhKjR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on text columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.key]\n",
        "    \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6uEvVS9KkWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,\n",
        "                 variety=\"BrE\",\n",
        "                 user_abbrevs={},\n",
        "                 n_jobs=1):\n",
        "        \"\"\"\n",
        "        Text preprocessing transformer includes steps:\n",
        "            1. Text normalization\n",
        "            2. Punctuation removal\n",
        "            3. Stop words removal\n",
        "            4. Lemmatization\n",
        "        \n",
        "        variety - format of date (AmE - american type, BrE - british format) \n",
        "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
        "        n_jobs - parallel jobs to run\n",
        "        \"\"\"\n",
        "        self.variety = variety\n",
        "        self.user_abbrevs = user_abbrevs\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, *_):\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        partitions = 1\n",
        "        cores = mp.cpu_count()\n",
        "        if self.n_jobs <= -1:\n",
        "            partitions = cores\n",
        "        elif self.n_jobs <= 0:\n",
        "            return X_copy.apply(self._preprocess_text)\n",
        "        else:\n",
        "            partitions = min(self.n_jobs, cores)\n",
        "\n",
        "        data_split = np.array_split(X_copy, partitions)\n",
        "        pool = mp.Pool(cores)\n",
        "        data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "\n",
        "        return data\n",
        "\n",
        "    def _preprocess_part(self, part):\n",
        "        return part.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        normalized_text = self._normalize(text)\n",
        "        doc = nlp(normalized_text)\n",
        "        removed_punct = self._remove_punct(doc)\n",
        "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
        "        return self._lemmatize(removed_stop_words)\n",
        "\n",
        "    def _normalize(self, text):\n",
        "        # some issues in normalise package\n",
        "        try:\n",
        "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
        "        except:\n",
        "            return text\n",
        "\n",
        "    def _remove_punct(self, doc):\n",
        "        return [t for t in doc if t.text not in string.punctuation]\n",
        "\n",
        "    def _remove_stop_words(self, doc):\n",
        "        return [t for t in doc if not t.is_stop]\n",
        "\n",
        "    def _lemmatize(self, doc):\n",
        "        return ' '.join([t.lemma_ for t in doc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMW9CFORRIt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhz87R5kRIw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set= pd.read_csv(\"Train_email.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ml9ztRRkNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set[\"Intent\"]= training_set[\"Intent\"].map({\"No\": 0, \"Yes\": 1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_FN0TtmSUyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEuvHUHBe9ny",
        "colab_type": "text"
      },
      "source": [
        "# Our Testing Dataset#\n",
        "\n",
        "We are trying to create a **TEXT PIPELINE SUPPORT FOR TPOT FRAMEWORK** \n",
        "\n",
        "TPOT doesnt support Text Pre-Processing on its own, hence we added ou own pipeline and integrated it with TPOT Auto-ML.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOOf9sSdRIz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a21d2d2b-4dcf-4cb7-b665-caa8cc6cd891"
      },
      "source": [
        "#creating a function to encapsulate our entire preprocessing and feature engineering steps\n",
        "def processing(df):\n",
        "    #get the no. of punctuations\n",
        "    df['specialchars'] = df['text'].apply(lambda x : len(x) - len(re.findall('[\\w]', x)))\n",
        "    #count the no. of words in the text\n",
        "    df['words'] = df['text'].apply(lambda x: len(x.split(' ')))\n",
        "    \n",
        "    return df\n",
        "    \n",
        "df= processing(training_set)   \n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Intent</th>\n",
              "      <th>text</th>\n",
              "      <th>specialchars</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>&gt;&gt;&gt; [1]Contact Me Now to Make $100 Today!$LINK</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Act now to keep your life on the go!</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Choose between $500 and $10000 dollars with up...</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Click above to earn today.</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Click here to receive your first $10 today:</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Intent  ... words\n",
              "0       0  ...     8\n",
              "1       0  ...     9\n",
              "2       0  ...    13\n",
              "3       0  ...     5\n",
              "4       0  ...     8\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jybBdiTSe8J0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQlVC6Y-RI2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "text = Pipeline([\n",
        "                ('selector', TextSelector(key='text')),\n",
        "                ('pre-processing', TextPreprocessor(n_jobs= -1)),\n",
        "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIKrkLUCSzPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "words =  Pipeline([\n",
        "                ('selector', NumberSelector(key='words')),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "specialchars =  Pipeline([\n",
        "                ('selector', NumberSelector(key='specialchars')),\n",
        "                ('standard', StandardScaler()),\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyEUQHsPTAUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "feats = FeatureUnion([('text', text),              \n",
        "                      ('words', words),\n",
        "                      ('specialchars', specialchars),\n",
        "                      ])\n",
        "feature_processing = Pipeline([('feats', feats)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPxszy5ZJaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpot_config = {\n",
        "    'sklearn.svm.LinearSVC': {\n",
        "    },\n",
        "    'sklearn.naive_bayes.GaussianNB': {\n",
        "    },\n",
        "    'sklearn.ensemble.RandomForestClassifier' : {\n",
        "    },\n",
        "    'sklearn.ensemble.GradientBoostingClassifier':{\n",
        "    }   \n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdI3uUgATJHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tpot import TPOTClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cE7EBukZFWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', feats),\n",
        "    ('classifier', TPOTClassifier(generations= 20, verbosity=2, max_time_mins=4, \n",
        "                                  max_eval_time_mins=0.04, population_size=20, config_dict=tpot_config))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHNTETZkZrqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X= df.drop(['Intent'], axis= 1)\n",
        "y= df[\"Intent\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBCpc8DHaTZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b95fa58-a229-40ec-c890-c3dedfaebb66"
      },
      "source": [
        "clf.fit(X_train, y_train)\n",
        "print(clf.score(X_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Since the input matrix is a sparse matrix, please makes sure all the operators in the customized config dictionary supports sparse matriies.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5d3ffab21e049ea8a5a373eacf15caf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=20, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 2 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 3 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 4 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 5 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 6 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 7 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 8 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 9 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 10 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 11 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 12 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 13 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 14 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 15 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 16 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 17 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 18 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 19 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 20 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 21 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 22 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 23 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 24 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 25 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 26 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 27 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 28 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 29 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 30 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 31 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 32 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 33 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 34 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 35 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 36 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 37 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 38 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 39 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 40 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 41 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 42 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 43 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 44 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 45 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 46 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 47 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 48 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 49 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 50 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 51 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 52 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 53 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 54 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 55 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 56 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 57 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 58 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 59 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 60 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 61 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 62 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 63 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 64 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 65 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 66 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 67 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 68 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 69 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 70 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 71 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 72 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 73 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 74 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 75 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 76 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 77 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 78 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 79 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 80 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 81 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 82 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 83 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 84 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 85 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 86 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 87 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 88 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 89 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 90 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 91 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 92 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 93 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 94 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 95 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 96 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 97 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 98 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 99 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 100 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 101 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 102 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 103 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 104 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 105 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 106 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 107 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 108 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 109 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 110 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 111 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 112 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 113 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 114 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 115 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 116 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 117 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 118 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 119 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 120 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 121 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 122 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 123 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 124 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 125 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 126 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 127 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 128 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 129 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 130 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 131 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 132 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 133 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 134 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 135 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 136 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 137 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 138 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 139 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 140 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 141 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 142 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 143 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 144 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 145 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 146 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 147 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 148 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 149 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 150 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 151 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 152 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 153 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 154 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 155 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 156 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 157 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 158 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 159 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 160 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 161 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 162 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 163 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 164 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 165 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 166 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 167 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 168 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 169 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 170 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 171 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 172 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 173 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 174 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 175 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 176 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 177 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 178 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 179 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 180 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 181 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 182 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 183 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 184 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 185 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 186 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 187 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 188 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 189 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 190 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 191 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 192 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 193 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 194 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 195 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 196 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 197 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 198 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 199 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 200 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 201 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 202 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 203 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 204 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 205 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 206 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 207 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 208 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 209 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 210 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 211 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 212 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 213 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 214 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 215 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 216 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 217 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 218 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 219 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 220 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 221 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 222 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 223 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 224 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 225 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 226 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 227 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 228 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 229 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 230 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 231 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 232 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 233 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 234 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 235 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 236 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 237 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 238 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 239 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 240 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 241 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 242 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 243 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 244 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 245 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 246 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 247 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 248 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 249 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 250 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 251 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 252 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 253 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 254 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 255 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 256 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 257 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 258 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 259 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 260 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 261 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 262 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 263 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 264 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 265 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 266 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 267 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 268 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 269 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 270 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 271 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 272 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 273 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 274 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 275 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 276 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 277 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 278 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 279 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 280 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 281 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 282 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 283 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 284 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 285 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 286 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 287 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 288 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 289 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 290 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 291 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 292 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 293 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 294 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 295 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 296 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 297 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 298 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 299 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 300 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 301 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 302 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 303 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 304 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 305 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 306 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 307 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 308 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 309 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 310 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 311 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 312 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 313 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 314 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 315 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 316 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 317 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 318 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 319 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 320 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 321 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 322 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 323 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 324 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 325 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 326 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 327 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 328 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 329 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 330 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 331 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 332 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 333 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 334 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 335 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 336 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 337 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 338 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 339 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 340 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 341 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 342 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 343 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 344 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 345 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 346 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 347 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 348 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 349 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 350 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 351 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 352 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 353 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 354 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 355 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 356 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 357 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 358 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 359 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 360 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 361 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 362 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 363 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 364 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 365 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 366 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 367 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 368 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 369 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 370 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 371 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 372 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 373 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 374 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 375 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 376 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 377 - Current best internal CV score: 0.6693867084806352\n",
            "Generation 378 - Current best internal CV score: 0.6693867084806352\n",
            "\n",
            "\n",
            "TPOT closed prematurely. Will use the current best pipeline.\n",
            "\n",
            "Best pipeline: LinearSVC(input_matrix)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-4:\n",
            "Process ForkPoolWorker-3:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"<ipython-input-4-b3859dce2d5b>\", line 45, in _preprocess_part\n",
            "    return part.apply(self._preprocess_text)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3591, in apply\n",
            "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
            "  File \"pandas/_libs/lib.pyx\", line 2217, in pandas._libs.lib.map_infer\n",
            "  File \"<ipython-input-4-b3859dce2d5b>\", line 49, in _preprocess_text\n",
            "    doc = nlp(normalized_text)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/language.py\", line 402, in __call__\n",
            "    doc = proc(doc, **component_cfg.get(name, {}))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
            "    return list(map(*args))\n",
            "  File \"nn_parser.pyx\", line 205, in spacy.syntax.nn_parser.Parser.__call__\n",
            "  File \"<ipython-input-4-b3859dce2d5b>\", line 45, in _preprocess_part\n",
            "    return part.apply(self._preprocess_text)\n",
            "  File \"nn_parser.pyx\", line 244, in spacy.syntax.nn_parser.Parser.predict\n",
            "  File \"nn_parser.pyx\", line 257, in spacy.syntax.nn_parser.Parser.greedy_parse\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 3591, in apply\n",
            "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 133, in predict\n",
            "    y, _ = self.begin_update(X, drop=None)\n",
            "  File \"pandas/_libs/lib.pyx\", line 2217, in pandas._libs.lib.map_infer\n",
            "  File \"<ipython-input-4-b3859dce2d5b>\", line 49, in _preprocess_text\n",
            "    doc = nlp(normalized_text)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/spacy/language.py\", line 402, in __call__\n",
            "    doc = proc(doc, **component_cfg.get(name, {}))\n",
            "  File \"_parser_model.pyx\", line 214, in spacy.syntax._parser_model.ParserModel.begin_update\n",
            "  File \"pipes.pyx\", line 392, in spacy.pipeline.pipes.Tagger.__call__\n",
            "  File \"_parser_model.pyx\", line 262, in spacy.syntax._parser_model.ParserStepModel.__init__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\", line 46, in begin_update\n",
            "    X, inc_layer_grad = layer.begin_update(X, drop=drop)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 295, in begin_update\n",
            "    X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad), drop=drop)\n",
            "  File \"pipes.pyx\", line 411, in spacy.pipeline.pipes.Tagger.predict\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\", line 46, in begin_update\n",
            "    X, inc_layer_grad = layer.begin_update(X, drop=drop)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 379, in uniqued_fwd\n",
            "    Y_uniq, bp_Y_uniq = layer.begin_update(X_uniq, drop=drop)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
            "    X = layer(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\", line 46, in begin_update\n",
            "    X, inc_layer_grad = layer.begin_update(X, drop=drop)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 310, in predict\n",
            "    X = layer(layer.ops.flatten(seqs_in, pad=pad))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 163, in begin_update\n",
            "    values = [fwd(X, *a, **k) for fwd in forward]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 163, in <listcomp>\n",
            "    values = [fwd(X, *a, **k) for fwd in forward]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 256, in wrap\n",
            "    output = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
            "    X = layer(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 163, in begin_update\n",
            "    values = [fwd(X, *a, **k) for fwd in forward]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 163, in <listcomp>\n",
            "    values = [fwd(X, *a, **k) for fwd in forward]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/resnet.py\", line 14, in predict\n",
            "    Y = self._layers[0](X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 256, in wrap\n",
            "    output = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
            "    X = layer(X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 163, in begin_update\n",
            "    values = [fwd(X, *a, **k) for fwd in forward]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 163, in <listcomp>\n",
            "    values = [fwd(X, *a, **k) for fwd in forward]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 169, in __call__\n",
            "    return self.predict(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\", line 53, in predict\n",
            "    N, mu, var = _get_moments(self.ops, X)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\", line 105, in _get_moments\n",
            "    mu = X.mean(axis=1, keepdims=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/api.py\", line 256, in wrap\n",
            "    output = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\", line 78, in _mean\n",
            "    ret, rcount, out=ret, casting='unsafe', subok=False)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/hash_embed.py\", line 60, in begin_update\n",
            "    vectors = self.vectors[keys].sum(axis=1)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-492f345e8b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    958\u001b[0m         Xs = Parallel(n_jobs=self.n_jobs)(\n\u001b[1;32m    959\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;31m# All transformers are None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b3859dce2d5b>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, *_)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdata_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTFrG5dScSii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPKGN0scSxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}